{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. set b = w = 0\n",
    "2. for N iterations, or until weights do not change\n",
    "       (a) for each training example xᵏ with label yᵏ\n",
    "           i. if yᵏ — f(xᵏ) = 0, continue\n",
    "           ii. else, update wᵢ, △wᵢ = (yᵏ — f(xᵏ)) xᵢ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Setting the random seed, feel free to change it and see different solutions.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data Files/Perceptron.csv',header=None)\n",
    "X = data.iloc[:,0:2].values\n",
    "y = data.iloc[:,2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.78051  , -0.063669 ],\n",
       "       [ 0.28774  ,  0.29139  ],\n",
       "       [ 0.40714  ,  0.17878  ],\n",
       "       [ 0.2923   ,  0.4217   ],\n",
       "       [ 0.50922  ,  0.35256  ],\n",
       "       [ 0.27785  ,  0.10802  ],\n",
       "       [ 0.27527  ,  0.33223  ],\n",
       "       [ 0.43999  ,  0.31245  ],\n",
       "       [ 0.33557  ,  0.42984  ],\n",
       "       [ 0.23448  ,  0.24986  ],\n",
       "       [ 0.0084492,  0.13658  ],\n",
       "       [ 0.12419  ,  0.33595  ],\n",
       "       [ 0.25644  ,  0.42624  ],\n",
       "       [ 0.4591   ,  0.40426  ],\n",
       "       [ 0.44547  ,  0.45117  ],\n",
       "       [ 0.42218  ,  0.20118  ],\n",
       "       [ 0.49563  ,  0.21445  ],\n",
       "       [ 0.30848  ,  0.24306  ],\n",
       "       [ 0.39707  ,  0.44438  ],\n",
       "       [ 0.32945  ,  0.39217  ],\n",
       "       [ 0.40739  ,  0.40271  ],\n",
       "       [ 0.3106   ,  0.50702  ],\n",
       "       [ 0.49638  ,  0.45384  ],\n",
       "       [ 0.10073  ,  0.32053  ],\n",
       "       [ 0.69907  ,  0.37307  ],\n",
       "       [ 0.29767  ,  0.69648  ],\n",
       "       [ 0.15099  ,  0.57341  ],\n",
       "       [ 0.16427  ,  0.27759  ],\n",
       "       [ 0.33259  ,  0.055964 ],\n",
       "       [ 0.53741  ,  0.28637  ],\n",
       "       [ 0.19503  ,  0.36879  ],\n",
       "       [ 0.40278  ,  0.035148 ],\n",
       "       [ 0.21296  ,  0.55169  ],\n",
       "       [ 0.48447  ,  0.56991  ],\n",
       "       [ 0.25476  ,  0.34596  ],\n",
       "       [ 0.21726  ,  0.28641  ],\n",
       "       [ 0.67078  ,  0.46538  ],\n",
       "       [ 0.3815   ,  0.4622   ],\n",
       "       [ 0.53838  ,  0.32774  ],\n",
       "       [ 0.4849   ,  0.26071  ],\n",
       "       [ 0.37095  ,  0.38809  ],\n",
       "       [ 0.54527  ,  0.63911  ],\n",
       "       [ 0.32149  ,  0.12007  ],\n",
       "       [ 0.42216  ,  0.61666  ],\n",
       "       [ 0.10194  ,  0.060408 ],\n",
       "       [ 0.15254  ,  0.2168   ],\n",
       "       [ 0.45558  ,  0.43769  ],\n",
       "       [ 0.28488  ,  0.52142  ],\n",
       "       [ 0.27633  ,  0.21264  ],\n",
       "       [ 0.39748  ,  0.31902  ],\n",
       "       [ 0.5533   ,  1.       ],\n",
       "       [ 0.44274  ,  0.59205  ],\n",
       "       [ 0.85176  ,  0.6612   ],\n",
       "       [ 0.60436  ,  0.86605  ],\n",
       "       [ 0.68243  ,  0.48301  ],\n",
       "       [ 1.       ,  0.76815  ],\n",
       "       [ 0.72989  ,  0.8107   ],\n",
       "       [ 0.67377  ,  0.77975  ],\n",
       "       [ 0.78761  ,  0.58177  ],\n",
       "       [ 0.71442  ,  0.7668   ],\n",
       "       [ 0.49379  ,  0.54226  ],\n",
       "       [ 0.78974  ,  0.74233  ],\n",
       "       [ 0.67905  ,  0.60921  ],\n",
       "       [ 0.6642   ,  0.72519  ],\n",
       "       [ 0.79396  ,  0.56789  ],\n",
       "       [ 0.70758  ,  0.76022  ],\n",
       "       [ 0.59421  ,  0.61857  ],\n",
       "       [ 0.49364  ,  0.56224  ],\n",
       "       [ 0.77707  ,  0.35025  ],\n",
       "       [ 0.79785  ,  0.76921  ],\n",
       "       [ 0.70876  ,  0.96764  ],\n",
       "       [ 0.69176  ,  0.60865  ],\n",
       "       [ 0.66408  ,  0.92075  ],\n",
       "       [ 0.65973  ,  0.66666  ],\n",
       "       [ 0.64574  ,  0.56845  ],\n",
       "       [ 0.89639  ,  0.7085   ],\n",
       "       [ 0.85476  ,  0.63167  ],\n",
       "       [ 0.62091  ,  0.80424  ],\n",
       "       [ 0.79057  ,  0.56108  ],\n",
       "       [ 0.58935  ,  0.71582  ],\n",
       "       [ 0.56846  ,  0.7406   ],\n",
       "       [ 0.65912  ,  0.71548  ],\n",
       "       [ 0.70938  ,  0.74041  ],\n",
       "       [ 0.59154  ,  0.62927  ],\n",
       "       [ 0.45829  ,  0.4641   ],\n",
       "       [ 0.79982  ,  0.74847  ],\n",
       "       [ 0.60974  ,  0.54757  ],\n",
       "       [ 0.68127  ,  0.86985  ],\n",
       "       [ 0.76694  ,  0.64736  ],\n",
       "       [ 0.69048  ,  0.83058  ],\n",
       "       [ 0.68122  ,  0.96541  ],\n",
       "       [ 0.73229  ,  0.64245  ],\n",
       "       [ 0.76145  ,  0.60138  ],\n",
       "       [ 0.58985  ,  0.86955  ],\n",
       "       [ 0.73145  ,  0.74516  ],\n",
       "       [ 0.77029  ,  0.7014   ],\n",
       "       [ 0.73156  ,  0.71782  ],\n",
       "       [ 0.44556  ,  0.57991  ],\n",
       "       [ 0.85275  ,  0.85987  ],\n",
       "       [ 0.51912  ,  0.62359  ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for x0, w0: [-0.11424183] Weight for x1, w1: [-0.27252549]  and bias 0.7897514529137677\n",
      "Weight for x0, w0: [-0.32965433] Weight for x1, w1: [-0.48670969]  and bias 0.4697514529137674\n",
      "Weight for x0, w0: [-0.34991053] Weight for x1, w1: [-0.50675519]  and bias 0.4297514529137674\n",
      "Weight for x0, w0: [-0.34666723] Weight for x1, w1: [-0.50662129]  and bias 0.4297514529137674\n",
      "Weight for x0, w0: [-0.35119463] Weight for x1, w1: [-0.50998989]  and bias 0.41975145291376736\n",
      "Weight for x0, w0: [-0.35087733] Weight for x1, w1: [-0.50765939]  and bias 0.41975145291376736\n",
      "Weight for x0, w0: [-0.35244793] Weight for x1, w1: [-0.50453659]  and bias 0.41975145291376736\n",
      "Weight for x0, w0: [-0.35401853] Weight for x1, w1: [-0.50141379]  and bias 0.41975145291376736\n",
      "Weight for x0, w0: [-0.35558913] Weight for x1, w1: [-0.49829099]  and bias 0.41975145291376736\n",
      "Weight for x0, w0: [-0.35715973] Weight for x1, w1: [-0.49516819]  and bias 0.41975145291376736\n",
      "Weight for x0, w0: [-0.35873033] Weight for x1, w1: [-0.49204539]  and bias 0.41975145291376736\n",
      "Weight for x0, w0: [-0.36030093] Weight for x1, w1: [-0.48892259]  and bias 0.41975145291376736\n",
      "Weight for x0, w0: [-0.36187153] Weight for x1, w1: [-0.48579979]  and bias 0.41975145291376736\n",
      "Weight for x0, w0: [-0.36344213] Weight for x1, w1: [-0.48267699]  and bias 0.41975145291376736\n",
      "Weight for x0, w0: [-0.36217843] Weight for x1, w1: [-0.48167409]  and bias 0.41975145291376736\n",
      "Weight for x0, w0: [-0.35893513] Weight for x1, w1: [-0.48154019]  and bias 0.41975145291376736\n",
      "Weight for x0, w0: [-0.35569183] Weight for x1, w1: [-0.48140629]  and bias 0.41975145291376736\n",
      "Weight for x0, w0: [-0.35244853] Weight for x1, w1: [-0.48127239]  and bias 0.41975145291376736\n",
      "Weight for x0, w0: [-0.34920523] Weight for x1, w1: [-0.48113849]  and bias 0.41975145291376736\n",
      "Weight for x0, w0: [-0.34596193] Weight for x1, w1: [-0.48100459]  and bias 0.41975145291376736\n",
      "Weight for x0, w0: [-0.34460653] Weight for x1, w1: [-0.48007839]  and bias 0.41975145291376736\n",
      "Weight for x0, w0: [-0.35102183] Weight for x1, w1: [-0.48265469]  and bias 0.40975145291376736\n",
      "Weight for x0, w0: [-0.35259243] Weight for x1, w1: [-0.47953189]  and bias 0.40975145291376736\n",
      "Weight for x0, w0: [-0.35416303] Weight for x1, w1: [-0.47640909]  and bias 0.40975145291376736\n",
      "Weight for x0, w0: [-0.35573363] Weight for x1, w1: [-0.47328629]  and bias 0.40975145291376736\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def stepFunction(t):\n",
    "    if t >= 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def prediction(X, W, b):\n",
    "    # (np.matmul(X,W)+b) takes arrays of X and W and returns an array with single value\n",
    "    return stepFunction((np.matmul(X,W)+b)[0]) # extract the value from array using [0]\n",
    "\n",
    "# TODO: Fill in the code below to implement the perceptron trick.\n",
    "# The function should receive as inputs the data X, the labels y,\n",
    "# the weights W (as an array), and the bias b,\n",
    "# update the weights and bias W, b, according to the perceptron algorithm,\n",
    "# and return W and b.\n",
    "def perceptronStep(X, y, W, b, learn_rate = 0.01):\n",
    "    for i in range(len(X)): # num of observations = len(X) = 100\n",
    "        y_hat = prediction(X[i],W,b) # for each pair of x0 and x1\n",
    "        if y[i]-y_hat == 1: # misclassification\n",
    "            W[0] = W[0] + X[i][0]*learn_rate # for each x0\n",
    "            W[1] = W[1] + X[i][1]*learn_rate # for each x1\n",
    "            b = b + learn_rate\n",
    "        elif y[i]-y_hat == -1: # misclassification\n",
    "            W[0] = W[0] - X[i][0]*learn_rate # for each x0\n",
    "            W[1] = W[1] - X[i][1]*learn_rate # for each x1\n",
    "            b = b + learn_rate\n",
    "    return W, b\n",
    "\n",
    "    \n",
    "# This function runs the perceptron algorithm repeatedly on the dataset,\n",
    "# and returns a few of the boundary lines obtained in the iterations,\n",
    "# for plotting purposes.\n",
    "def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0]) # may be omitted\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1]) # may be omitted\n",
    "    W = np.array(np.random.rand(2,1)) \n",
    "    b = np.random.rand(1)[0] + x_max # Scalar Value\n",
    "    # or\n",
    "    # W = np.zeros([X.shape[1],1])\n",
    "    # b = 0 \n",
    "    \n",
    "    # These are the solution lines that get plotted below.\n",
    "    boundary_lines = []\n",
    "    for i in range(num_epochs):\n",
    "        # In each epoch, we apply the perceptron step.\n",
    "        W, b = perceptronStep(X, y, W, b, learn_rate) # Updates W and b for each epoch\n",
    "        # intial weight W = array([[0.],[0.]]) for x0 and X1\n",
    "        # X as an array of lists for each value of x0 and x1 :  array([[ 0.78051 , -0.063669],[0.28774, 0.29139],...]) )\n",
    "        # y as an array :  array([1, 1, 0, 0,....])\n",
    "        print('Weight for x0, w0:',W[0],'Weight for x1, w1:',W[1],' and bias',b)\n",
    "        boundary_lines.append((-W[0]/W[1], -b/W[1]))\n",
    "    return boundary_lines\n",
    "\n",
    "boundary_lines = trainPerceptronAlgorithm(X,y)\n",
    "#boundary_lines"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.scatter(boundary_lines[:100,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.78051  , -0.063669 ],\n",
       "       [ 0.28774  ,  0.29139  ],\n",
       "       [ 0.40714  ,  0.17878  ],\n",
       "       [ 0.2923   ,  0.4217   ],\n",
       "       [ 0.50922  ,  0.35256  ],\n",
       "       [ 0.27785  ,  0.10802  ],\n",
       "       [ 0.27527  ,  0.33223  ],\n",
       "       [ 0.43999  ,  0.31245  ],\n",
       "       [ 0.33557  ,  0.42984  ],\n",
       "       [ 0.23448  ,  0.24986  ],\n",
       "       [ 0.0084492,  0.13658  ],\n",
       "       [ 0.12419  ,  0.33595  ],\n",
       "       [ 0.25644  ,  0.42624  ],\n",
       "       [ 0.4591   ,  0.40426  ],\n",
       "       [ 0.44547  ,  0.45117  ],\n",
       "       [ 0.42218  ,  0.20118  ],\n",
       "       [ 0.49563  ,  0.21445  ],\n",
       "       [ 0.30848  ,  0.24306  ],\n",
       "       [ 0.39707  ,  0.44438  ],\n",
       "       [ 0.32945  ,  0.39217  ],\n",
       "       [ 0.40739  ,  0.40271  ],\n",
       "       [ 0.3106   ,  0.50702  ],\n",
       "       [ 0.49638  ,  0.45384  ],\n",
       "       [ 0.10073  ,  0.32053  ],\n",
       "       [ 0.69907  ,  0.37307  ],\n",
       "       [ 0.29767  ,  0.69648  ],\n",
       "       [ 0.15099  ,  0.57341  ],\n",
       "       [ 0.16427  ,  0.27759  ],\n",
       "       [ 0.33259  ,  0.055964 ],\n",
       "       [ 0.53741  ,  0.28637  ],\n",
       "       [ 0.19503  ,  0.36879  ],\n",
       "       [ 0.40278  ,  0.035148 ],\n",
       "       [ 0.21296  ,  0.55169  ],\n",
       "       [ 0.48447  ,  0.56991  ],\n",
       "       [ 0.25476  ,  0.34596  ],\n",
       "       [ 0.21726  ,  0.28641  ],\n",
       "       [ 0.67078  ,  0.46538  ],\n",
       "       [ 0.3815   ,  0.4622   ],\n",
       "       [ 0.53838  ,  0.32774  ],\n",
       "       [ 0.4849   ,  0.26071  ],\n",
       "       [ 0.37095  ,  0.38809  ],\n",
       "       [ 0.54527  ,  0.63911  ],\n",
       "       [ 0.32149  ,  0.12007  ],\n",
       "       [ 0.42216  ,  0.61666  ],\n",
       "       [ 0.10194  ,  0.060408 ],\n",
       "       [ 0.15254  ,  0.2168   ],\n",
       "       [ 0.45558  ,  0.43769  ],\n",
       "       [ 0.28488  ,  0.52142  ],\n",
       "       [ 0.27633  ,  0.21264  ],\n",
       "       [ 0.39748  ,  0.31902  ],\n",
       "       [ 0.5533   ,  1.       ],\n",
       "       [ 0.44274  ,  0.59205  ],\n",
       "       [ 0.85176  ,  0.6612   ],\n",
       "       [ 0.60436  ,  0.86605  ],\n",
       "       [ 0.68243  ,  0.48301  ],\n",
       "       [ 1.       ,  0.76815  ],\n",
       "       [ 0.72989  ,  0.8107   ],\n",
       "       [ 0.67377  ,  0.77975  ],\n",
       "       [ 0.78761  ,  0.58177  ],\n",
       "       [ 0.71442  ,  0.7668   ],\n",
       "       [ 0.49379  ,  0.54226  ],\n",
       "       [ 0.78974  ,  0.74233  ],\n",
       "       [ 0.67905  ,  0.60921  ],\n",
       "       [ 0.6642   ,  0.72519  ],\n",
       "       [ 0.79396  ,  0.56789  ],\n",
       "       [ 0.70758  ,  0.76022  ],\n",
       "       [ 0.59421  ,  0.61857  ],\n",
       "       [ 0.49364  ,  0.56224  ],\n",
       "       [ 0.77707  ,  0.35025  ],\n",
       "       [ 0.79785  ,  0.76921  ],\n",
       "       [ 0.70876  ,  0.96764  ],\n",
       "       [ 0.69176  ,  0.60865  ],\n",
       "       [ 0.66408  ,  0.92075  ],\n",
       "       [ 0.65973  ,  0.66666  ],\n",
       "       [ 0.64574  ,  0.56845  ],\n",
       "       [ 0.89639  ,  0.7085   ],\n",
       "       [ 0.85476  ,  0.63167  ],\n",
       "       [ 0.62091  ,  0.80424  ],\n",
       "       [ 0.79057  ,  0.56108  ],\n",
       "       [ 0.58935  ,  0.71582  ],\n",
       "       [ 0.56846  ,  0.7406   ],\n",
       "       [ 0.65912  ,  0.71548  ],\n",
       "       [ 0.70938  ,  0.74041  ],\n",
       "       [ 0.59154  ,  0.62927  ],\n",
       "       [ 0.45829  ,  0.4641   ],\n",
       "       [ 0.79982  ,  0.74847  ],\n",
       "       [ 0.60974  ,  0.54757  ],\n",
       "       [ 0.68127  ,  0.86985  ],\n",
       "       [ 0.76694  ,  0.64736  ],\n",
       "       [ 0.69048  ,  0.83058  ],\n",
       "       [ 0.68122  ,  0.96541  ],\n",
       "       [ 0.73229  ,  0.64245  ],\n",
       "       [ 0.76145  ,  0.60138  ],\n",
       "       [ 0.58985  ,  0.86955  ],\n",
       "       [ 0.73145  ,  0.74516  ],\n",
       "       [ 0.77029  ,  0.7014   ],\n",
       "       [ 0.73156  ,  0.71782  ],\n",
       "       [ 0.44556  ,  0.57991  ],\n",
       "       [ 0.85275  ,  0.85987  ],\n",
       "       [ 0.51912  ,  0.62359  ]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28774, 0.29139])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28774"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42754102],\n",
       "       [0.02541913]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.random.rand(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13042753])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul([0.28774, 0.29139],[[0.42754102],[0.02541913]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros([X.shape[1],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6842330265121569"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0084492, 1.0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(X.T[0]), max(X.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51423444],\n",
       "       [0.59241457]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(X.shape[1]) #Random initial Weights for X0 and X1\n",
    "#np.array(np.random.rand(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You got 1 wrong.  Keep trying!\n",
      "\n",
      " Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "       0          0                  -1.0                    0          Yes\n",
      "       0          1                  -1.0                    0          Yes\n",
      "       1          0                   0.0                    1           No\n",
      "       1          1                   0.0                    1          Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = 1.0\n",
    "weight2 = 0.0\n",
    "bias = -1.0\n",
    "\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, False, False, True]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = 0.0\n",
    "weight2 = 0.0\n",
    "bias = 0.0\n",
    "\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [True, False, True, False]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    URL_='https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "    data = pd.read_csv(URL_, header = None)\n",
    "    #print(data)\n",
    "    \n",
    "    # make the dataset linearly separable\n",
    "    data = data[:100]\n",
    "    data[4] = np.where(data.iloc[:, -1]=='Iris-setosa', 0, 1)\n",
    "    data = np.asmatrix(data, dtype = 'float64')\n",
    "    return data\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.array(data[:50,0]), np.array(data[:50,2]), marker='o', label='setosa')\n",
    "plt.scatter(np.array(data[50:,0]), np.array(data[50:,2]), marker='x', label='versicolor')\n",
    "plt.xlabel('petal length')\n",
    "plt.ylabel('sepal length')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 4 features and hence 4 weights associated with each feature.\n",
    "# Remember that we defined a bias term w₀ that assumes x₀=1 making it a total of 5 weights.\n",
    "# number of iterations = 10 : hyperparameters\n",
    "# system parameters like w that are learned by the algorithm. \n",
    "# At each iteration, the algorithm computes the class (0 or 1) for all the data points and updates the weights with each \n",
    "# misclassification.\n",
    "# dataset contains 4 features that describe the flower and classify them as belonging to one of the 3 classes\n",
    "# We strip the last 50 rows of the dataset that belongs to the class ‘Iris-virginica’ and use only 2 classes \n",
    "# ‘Iris-setosa’ and ‘Iris-versicolor’ because these classes are linearly separable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "def perceptron(data, num_iter):\n",
    "    features = data[:, :-1]\n",
    "    labels = data[:, -1]\n",
    "    \n",
    "    # set weights to zero\n",
    "    w = np.zeros(shape=(1, features.shape[1]+1))\n",
    "    \n",
    "    misclassified_ = [] \n",
    "  \n",
    "    for epoch in range(num_iter):\n",
    "        misclassified = 0\n",
    "        for x, label in zip(features, labels):\n",
    "            x = np.insert(x,0,1)\n",
    "            y = np.dot(w, x.transpose()) # calcuate the dot product w.x_T ~ 1*n, n*1\n",
    "            target = 1.0 if (y > 0) else 0.0 # step function\n",
    "            \n",
    "#             delta = (label.item(0,0) - target)\n",
    "            \n",
    "#             if(delta): # misclassified\n",
    "#                 misclassified += 1\n",
    "#                 w += (delta * x)\n",
    "        \n",
    "#         misclassified_.append(misclassified)\n",
    "    return (w, misclassified_)\n",
    "             \n",
    "num_iter = 10\n",
    "w, misclassified_ = perceptron(data, num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1, num_iter+1)\n",
    "plt.plot(epochs, misclassified_)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('misclassified')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data[:, :-1]\n",
    "labels = data[:, -1]\n",
    "np.zeros(shape=(1, features.shape[1]+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://medium.com/@thomascountz/19-line-line-by-line-python-perceptron-b6f113b161f3\n",
    "- def perceptron(inputs, bias)\n",
    "- weighted_sum = sum {\n",
    "    - for each input in inputs\n",
    "    -   input.value * input.weight\n",
    "  }\n",
    "- if weighted_sum <= bias\n",
    "    -   return 0\n",
    "- if weighted_sum > bias\n",
    "    -   return 1\n",
    "- end\n",
    "- (w1 * x1) + (w2 * x2) + ... + (wn * xn) + (b * 1)\n",
    "- sometimes b as (w0 * x0), where x0 = 1\n",
    "- f(x) = 1 , if w · x > 0 and f(x) = 0, otherwise\n",
    "- Our inputs x ... xn will never be changed by our learning algorithm, and therefore, neither will our new input,1\n",
    "- expected_output - actual_output closer to 0\n",
    "- If the perceptron outputs 1, (f(x) = 1), when we wanted 0, (y = 0), we’ll want to adjust it by making w · x  -     smaller, because in order to get f(x) = 0, w · x must be <= 0.\n",
    "- Likewise, if the perceptron outputs 0, (f(x) = 0), when we wanted 1, (y = 1), we’ll want to adjust it by making     w·x larger, because in order to get f(x) = 1, w · x must be > 0.\n",
    "- And finally, if the perceptron outputs what we expected, f(x) == y, we’ll want to adjust nothing,\n",
    "- w <- w + (y - f(x)) * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "class Perceptron(object):\n",
    "\n",
    "    def __init__(self, no_of_inputs, threshold=100, learning_rate=0.01):\n",
    "        self.threshold = threshold\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.zeros(no_of_inputs + 1)\n",
    "           \n",
    "    def predict(self, inputs):\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
    "        if summation > 0:\n",
    "            activation = 1\n",
    "        else:\n",
    "            activation = 0            \n",
    "        return activation\n",
    "\n",
    "    def train(self, training_inputs, labels):\n",
    "        for _ in range(self.threshold):\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                self.weights[1:] += self.learning_rate * (label - prediction) * inputs\n",
    "                self.weights[0] += self.learning_rate * (label - prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
